{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.GoogleSearchScrapper import GoogleSearchModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of GoogleSearchModule with the topic you want to search for\n",
    "search_module = GoogleSearchModule(\"Write a post about the benefits of using a chatbot on a website.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get URLs, filtered to exclude certain social media sites\n",
    "filtered_urls = search_module.get_url(\"Write a post about the benefits of using a chatbot on a website.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the filtered URLs\n",
    "print(filtered_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_documents = []\n",
    "for url in filtered_urls:\n",
    "    loader = WebBaseLoader(url)\n",
    "    loaded_documents += loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_docs(loaded_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(loaded_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Write a short post on the benefits of using a chatbot on a website.\"\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = FlashrankRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs = compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema import HumanMessage\n",
    "from camel_pipeline import camel_pipeline\n",
    "from rag import return_filtered_urls, return_camel_response_doc, return_url_doc, ingest_all, retrieval_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_role_name = \"Content Writer\"\n",
    "user_role_name = \"Founder and CEO\"\n",
    "user_task = \"Write a post about the benefits of using a chatbot on a website.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specified_task, camel_response = camel_pipeline(assistant_role_name, user_role_name, user_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specified_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camel_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = return_filtered_urls(specified_task)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camel_response_doc = return_camel_response_doc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_doc = return_url_doc(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = camel_response_doc + url_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = retrieval_pipeline(faiss_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_docs = retriever.invoke(specified_task)\n",
    "pretty_print_docs(ranked_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 20:41:59,230 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:01,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:02,907 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:03,906 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:05,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:06,425 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:08,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:09,341 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:12,340 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:13,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:14,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:18,548 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 20:42:18,775 - INFO - Loading faiss with AVX2 support.\n",
      "2024-06-04 20:42:18,842 - INFO - Successfully loaded faiss with AVX2 support.\n",
      "2024-06-04 20:42:20,615 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "### Setting up the CAMEL-RAG pipeline\n",
    "# Importing Dependencies\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "from camel_pipeline import camel_pipeline\n",
    "from rag import (return_filtered_urls, return_camel_response_doc, return_url_doc, \n",
    "                ingest_all, retrieval_pipeline, pretty_print_docs, get_llm_chain,\n",
    "                get_custom_prompt_template)\n",
    "\n",
    "# Load the Environment Variables\n",
    "load_dotenv()\n",
    "# Set up the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "# Define the roles and task\n",
    "assistant_role_name = \"Content Writer\"\n",
    "user_role_name = \"Founder and CEO\"\n",
    "user_task = \"Write a linkedin post on brainstorming and visioning techniques.\"\n",
    "\n",
    "# Run the CAMEL pipeline\n",
    "specified_task, camel_response = camel_pipeline(assistant_role_name, user_role_name, user_task)\n",
    "# Get the URLs for the specified task\n",
    "urls = return_filtered_urls(specified_task)\n",
    "# Get the CAMEL response document\n",
    "camel_response_doc = return_camel_response_doc()\n",
    "# Get the URL document\n",
    "url_doc = return_url_doc(urls)\n",
    "# Combine the CAMEL response document and URL document\n",
    "docs = camel_response_doc + url_doc\n",
    "# Injest all the documents from the web into FAISS vectorstore\n",
    "db = ingest_all(docs)\n",
    "# Create the retrieval pipeline\n",
    "retriever = retrieval_pipeline(db)\n",
    "# Retrieve the ranked documents\n",
    "ranked_docs = retriever.invoke(specified_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a LinkedIn post discussing the use of virtual reality technology in brainstorming and visioning techniques, highlighting its potential to enhance creativity and collaboration in remote work environments. Include examples of successful implementation and encourage professionals to explore this innovative approach.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specified_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Virtual reality technology is revolutionizing the way we approach brainstorming and visioning techniques in the remote work environment. As professionals navigate the challenges of collaborating from different locations, VR offers an innovative solution to enhance creativity and foster effective teamwork. This post will explore the potential of VR in transforming the way we ideate and visualize, ultimately leading to more impactful outcomes.One notable example of successful implementation of virtual reality technology in brainstorming and visioning techniques is seen in the automotive industry. Companies like Ford and Audi have utilized VR to create immersive virtual environments where teams can visualize and iterate on vehicle designs, leading to more efficient and collaborative ideation processes. This has resulted in accelerated innovation and improved design outcomes.Professionals across industries are encouraged to explore the innovative approach of using virtual reality technology for brainstorming and visioning in remote work environments. Embracing VR can unlock new levels of creativity, collaboration, and productivity, ultimately leading to more impactful outcomes in the virtual workspace. By leveraging this cutting-edge technology, teams can transcend geographical barriers and engage in dynamic, immersive brainstorming sessions that drive innovation and foster a sense of togetherness. It's time to harness the power of VR to elevate remote collaboration to unprecedented heights.In conclusion, virtual reality technology holds immense potential in enhancing creativity and collaboration in remote work environments. By providing immersive and interactive platforms for brainstorming and visioning, VR empowers teams to transcend physical limitations and co-create in unprecedented ways. As professionals continue to navigate the evolving landscape of remote work, embracing VR as a tool for ideation and visualization can lead to breakthrough innovations and strengthened team dynamics. It's time to embrace the future of remote collaboration with virtual reality.Great! If you need any further assistance or revisions, feel free to ask.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camel_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Virtual reality technology is revolutionizing the way we approach brainstorming and visioning techniques in the remote work environment. As professionals navigate the challenges of collaborating from different locations, VR offers an innovative solution to enhance creativity and foster effective teamwork. This post will explore the potential of VR in transforming the way we ideate and visualize, ultimately leading to more impactful outcomes.One notable example of successful implementation of virtual reality technology in brainstorming and visioning techniques is seen in the automotive industry. Companies like Ford and Audi have utilized VR to create immersive virtual environments where teams can visualize and iterate on vehicle designs, leading to more efficient and collaborative ideation processes. This has resulted in accelerated innovation and improved design outcomes.Professionals across industries are encouraged to explore the innovative approach of using virtual reality', metadata={'source': 'D:\\\\AIML\\\\CAMEL-RAG\\\\camel_response.txt', 'relevance_score': 0.99931717}),\n",
       " Document(page_content=\"across industries are encouraged to explore the innovative approach of using virtual reality technology for brainstorming and visioning in remote work environments. Embracing VR can unlock new levels of creativity, collaboration, and productivity, ultimately leading to more impactful outcomes in the virtual workspace. By leveraging this cutting-edge technology, teams can transcend geographical barriers and engage in dynamic, immersive brainstorming sessions that drive innovation and foster a sense of togetherness. It's time to harness the power of VR to elevate remote collaboration to unprecedented heights.In conclusion, virtual reality technology holds immense potential in enhancing creativity and collaboration in remote work environments. By providing immersive and interactive platforms for brainstorming and visioning, VR empowers teams to transcend physical limitations and co-create in unprecedented ways. As professionals continue to navigate the evolving landscape of remote work,\", metadata={'source': 'D:\\\\AIML\\\\CAMEL-RAG\\\\camel_response.txt', 'relevance_score': 0.99931484}),\n",
       " Document(page_content=\"in unprecedented ways. As professionals continue to navigate the evolving landscape of remote work, embracing VR as a tool for ideation and visualization can lead to breakthrough innovations and strengthened team dynamics. It's time to embrace the future of remote collaboration with virtual reality.Great! If you need any further assistance or revisions, feel free to ask.\", metadata={'source': 'D:\\\\AIML\\\\CAMEL-RAG\\\\camel_response.txt', 'relevance_score': 0.99900913})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "for doc in ranked_docs:\n",
    "    context += doc.page_content + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_specified' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the custom prompt template\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mget_custom_prompt_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43massistant_role_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_role_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Get the LLM chain\u001b[39;00m\n\u001b[0;32m      4\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m get_llm_chain(retriever, prompt)\n",
      "File \u001b[1;32md:\\AIML\\CAMEL-RAG\\rag\\prompt.py:11\u001b[0m, in \u001b[0;36mget_custom_prompt_template\u001b[1;34m(assistant_role_name, user_role_name, context)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_custom_prompt_template\u001b[39m(assistant_role_name, user_role_name, context):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Custom prompt template\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     custom_prompt_template \u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    You are a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00massistant_role_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Your role is to provide assistance to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_role_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in completing the task. \u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m    You can refer to the context below to generate a response to the user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms task and respond with your expertise.\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m    Contex: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;124m    Task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtask_specified\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m    You are excellent at writing plagrism free content with 100% human-like writing skills and \u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m    SEO optimized content for improved search engine visiibility.\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m    Response:\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Create the custom prompt\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     custom_prompt \u001b[38;5;241m=\u001b[39m custom_prompt_template\u001b[38;5;241m.\u001b[39mformat(assistant_role_name\u001b[38;5;241m=\u001b[39massistant_role_name,\n\u001b[0;32m     18\u001b[0m                                                     user_role_name\u001b[38;5;241m=\u001b[39muser_role_name,\n\u001b[0;32m     19\u001b[0m                                                     context\u001b[38;5;241m=\u001b[39mcontext)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'task_specified' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the custom prompt template\n",
    "prompt = get_custom_prompt_template(assistant_role_name, user_role_name, context)\n",
    "# Get the LLM chain\n",
    "llm_chain = get_llm_chain(retriever, prompt)\n",
    "# Get the response from the LLM chain\n",
    "response = llm_chain(specified_task)\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag import get_custom_prompt_template\n",
    "from rag_pipeline import rag_pipeline_context, rag_pipeline_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_role_name = \"Content Writer\"\n",
    "user_role_name = \"Founder and CEO\"\n",
    "specified_task= 'Write a LinkedIn post discussing the use of virtual reality technology in brainstorming and visioning techniques, highlighting its potential to enhance creativity and collaboration in remote work environments. Include examples of successful implementation and encourage professionals to explore this innovative approach.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 23:13:36,574 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-04 23:13:36,801 - INFO - Loading faiss with AVX2 support.\n",
      "2024-06-04 23:13:36,821 - INFO - Successfully loaded faiss with AVX2 support.\n",
      "2024-06-04 23:13:38,224 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "context = rag_pipeline_context(assistant_role_name, user_role_name, specified_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['specified_task'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a Content Writer. Your role is to provide assistance to Founder and CEO in completing the task. \\n    You can refer to the context below to generate a response to the user\\'s task and respond with your expertise.\\n    Contex: Fostering innovation and problem-solving within a remote team environment presents unique challenges that demand unconventional brainstorming techniques.I\\'m sorry, I cannot fulfill this request as I do not have personal anecdotes or case studies to share.In a hypothetical scenario, a remote team faced a complex problem that required innovative solutions. By using unconventional brainstorming techniques such as \"reverse thinking\" and \"random word association\" during a virtual brainstorming session, the team was able to generate out-of-the-box ideas and effectively solve the challenge, leading to increased productivity and a sense of camaraderie among team members.The remote team experienced enhanced creativity, improved problem-solving skills, increased engagement, and a stronger sense of collaboration and unity as a result of using unconventional brainstorming techniques in the hypothetical scenario. These benefits ultimately led to the successful resolution of the complex problem and\\n\\nscenario. These benefits ultimately led to the successful resolution of the complex problem and a more innovative team dynamic.Great! If you need any further assistance, feel free to ask.\\n\\n\\n    You are excellent at writing plagrism free content with 100% human-like writing skills and SEO optimized content for improved search engine visiibility.\\n    ')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['specified_task'], template='Task: {specified_task} \\n\\n Response:'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = get_custom_prompt_template(assistant_role_name, user_role_name, context)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
